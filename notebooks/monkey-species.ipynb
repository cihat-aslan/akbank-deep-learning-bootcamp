{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":44567,"sourceType":"datasetVersion","datasetId":10449}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Akbank Derin Öğrenme Bootcamp Projesi: Maymun Türleri Sınıflandırması\n\nBu proje, Akbank Derin Öğrenme Bootcamp'i kapsamında gerçekleştirilmiştir. Projenin temel amacı, Evrişimli Sinir Ağları (CNN) kullanarak bir görüntü sınıflandırma problemini baştan sona uygulamaktır. Veri seti olarak Kaggle'da bulunan ve 10 farklı maymun türüne ait görseller içeren \"10 Monkey Species\" veri seti seçilmiştir. Bu notebook, veri ön işleme, model geliştirme, eğitim, değerlendirme ve optimizasyon adımlarını içermektedir.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport warnings\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Veri Setinin İncelenmesi ve Keşfi (Exploratory Data Analysis - EDA)\nBu bölümde ilk olarak veri setimizin yapısı incelenmektedir. `matplotlib` ve `seaborn` kütüphaneleri kullanılarak her bir sınıftaki (maymun türü) görüntü sayısı görselleştirilmiş ve sınıflar arasında dengeli bir dağılım olduğu gözlemlenmiştir. Ayrıca, her sınıftan rastgele birer örnek görseli ekrana çizdirilerek veri seti hakkında genel bir fikir edinilmiştir.","metadata":{}},{"cell_type":"code","source":"base_dir = '../input/10-monkey-species'\ntrain_dir = os.path.join(base_dir, 'training/training')\nvalidation_dir = os.path.join(base_dir, 'validation/validation')\n\nclass_names = os.listdir(train_dir)\nclass_names.sort()\nprint(\"Toplam sınıf (maymun türü) sayısı:\", len(class_names))\nprint(\"Sınıf isimleri:\", class_names)\n\ntrain_dir = '/kaggle/input/10-monkey-species/training/training'\nclass_names = os.listdir(train_dir)\nimage_counts = {}\nfor class_name in class_names:\n    class_path = os.path.join(train_dir, class_name)\n    image_counts[class_name] = len(os.listdir(class_path))\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x=list(image_counts.keys()), y=list(image_counts.values()))\nplt.title('Her Sınıftaki Eğitim Görüntüsü Sayısı')\nplt.xlabel('Maymun Türü')\nplt.ylabel('Görüntü Sayısı')\nplt.xticks(rotation=45)\nplt.show()\nwarnings.filterwarnings(\"ignore\")\n\nimport random\nfrom tensorflow.keras.preprocessing.image import load_img\n\nplt.figure(figsize=(15, 10))\n\nfor i, class_name in enumerate(class_names):\n    # Her sınıf klasöründen rastgele bir resim seç\n    class_path = os.path.join(train_dir, class_name)\n    random_image = random.choice(os.listdir(class_path))\n    image_path = os.path.join(class_path, random_image)\n\n    img = load_img(image_path)\n    ax = plt.subplot(2, 5, i + 1)\n    plt.imshow(img)\n    plt.title(f\"{i}: {class_name}\") # .split() kısmını kaldırdık\n    plt.axis(\"off\")\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Veri Ön İşleme ve Veri Çoğaltma (Data Preprocessing & Augmentation)\nBu aşamada, görseller modelin işleyebileceği formata getirilmiştir. `ImageDataGenerator` kullanılarak veri ön işleme ve çoğaltma (Data Augmentation) adımları gerçekleştirilmiştir.\n\n* **Veri Çoğaltma:** Modelin genelleme yeteneğini artırmak ve ezberlemesini (overfitting) önlemek amacıyla eğitim setindeki görüntülere rastgele döndürme (rotation), yakınlaştırma (zoom) ve yatay çevirme (flip) gibi çeşitli dönüşümler uygulanmıştır.\n* **Ön İşleme:** Kullandığımız `EfficientNetB0` modeli kendi içinde bir ön işleme (rescale) katmanına sahip olduğu için, veri jeneratöründe ayrıca bir piksel normalizasyonu (`rescale=1./255`) yapılmamıştır. Veriler modele orijinal piksel değerleri (0-255) ile beslenmiştir.","metadata":{}},{"cell_type":"code","source":"IMG_HEIGHT = 150\nIMG_WIDTH = 150\nBATCH_SIZE = 32\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nprint(\"Eğitim verisi hazırlanıyor...\")\ntrain_datagen = ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nprint(\"Doğrulama verisi hazırlanıyor...\")\nvalidation_datagen = ImageDataGenerator() \n\ntrain_generator = train_datagen.flow_from_directory(\n    directory=train_dir,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical'\n)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    directory=validation_dir,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False\n)\nprint(\"Veri jeneratörleri başarıyla oluşturuldu.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Model Mimarisi: Transfer Learning ile EfficientNetB0\nProjenin bu aşamasında, yüksek başarı oranına ulaşmak için **Transfer Learning (Transfer Öğrenme)** tekniği kullanılmıştır. Sıfırdan bir CNN modeli eğitmek yerine, Google tarafından geliştirilen ve ImageNet veri setinde eğitilmiş olan `EfficientNetB0` modeli temel (base) olarak alınmıştır.\n\nModelin mimarisi şu şekildedir:\n1.  **Temel Model:** `EfficientNetB0` modelinin en üstündeki sınıflandırma katmanı olmadan (`include_top=False`) yüklenmiştir.\n2.  **Dondurma (Freezing):** `EfficientNetB0`'ın önceden öğrenilmiş olan ağırlıklarının bozulmaması için temel modelin tüm katmanları dondurulmuştur.\n3.  **Özel Sınıflandırıcı Katmanları:** Dondurulmuş temel modelin çıktısına, kendi problemimize özel bir sınıflandırıcı eklenmiştir. Bu sınıflandırıcıda `GlobalAveragePooling2D`, `Dense` ve `Dropout` katmanları kullanılmıştır. Çıkış katmanında 10 sınıfımız için `softmax` aktivasyon fonksiyonu tercih edilmiştir.","metadata":{}},{"cell_type":"code","source":"# --- TRANSFER LEARNING MODELİ KURULUMU, EĞİTİMİ VE DEĞERLENDİRMESİ ---\n\n# Gerekli kütüphaneler\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Adım 1: Önceden eğitilmiş EfficientNetB0 modelinin yüklenmesi\nbase_model = EfficientNetB0(weights='imagenet', include_top=False,\n                            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n\n# Adım 2: Temel modelin katmanlarının dondurulmesi\nbase_model.trainable = False\n\n# Adım 3: Kendi sınıflandırıcımızı temel modelin üzerine eklenmesi\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\noutputs = Dense(10, activation='softmax')(x)\n\n# Adım 4: Yeni model oluşturulur ve derlenir\nmodel = Model(inputs=base_model.input, outputs=outputs)\n\n# Transfer learning için düşük bir öğrenme oranı kullanıyoruz.\nmodel.compile(optimizer=Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nprint(\"--- TRANSFER LEARNING MODELİ BAŞARIYLA OLUŞTURULDU ---\")\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Modelin Eğitilmesi\nModel, `Adam` optimize edici ve `categorical_crossentropy` kayıp fonksiyonu ile derlenmiştir. Transfer Learning tekniğinde, önceden eğitilmiş ağırlıklara hassas bir şekilde adapte olabilmek için düşük bir öğrenme oranı (`learning_rate=0.0001`) seçilmiştir.","metadata":{}},{"cell_type":"code","source":"# Adım 5: Yeni modelin eğitilmesi\nEPOCHS = 30\nprint(f\"\\n--- TRANSFER LEARNING EĞİTİMİ BAŞLATILIYOR ({EPOCHS} EPOCH) ---\")\n\nhistory = model.fit(\n    train_generator,\n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n    validation_steps=validation_generator.samples // BATCH_SIZE\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Eğitim Sürecinin Değerlendirilmesi\nModel 30 epoch boyunca eğitilmiştir. Aşağıdaki grafikler, eğitim süresince modelin doğruluk ve kayıp metriklerinin değişimini göstermektedir. Grafiklerin incelenmesi, modelin başarılı bir şekilde öğrenip öğrenmediğini ve ezberleme (overfitting) problemi yaşayıp yaşamadığını anlamak için kritik öneme sahiptir.","metadata":{}},{"cell_type":"code","source":"# Adım 6: Eğitim sonuçlarının görselleştirilmesi\nprint(\"\\n--- EĞİTİM GRAFİKLERİ OLUŞTURULUYOR ---\")\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(15, 6))\nplt.subplot(1, 2, 1)\nplt.plot(range(EPOCHS), acc, label='Eğitim Doğruluğu')\nplt.plot(range(EPOCHS), val_acc, label='Doğrulama Doğruluğu')\nplt.legend(loc='lower right')\nplt.title('Eğitim ve Doğrulama Doğruluğu')\nplt.subplot(1, 2, 2)\nplt.plot(range(EPOCHS), loss, label='Eğitim Kaybı')\nplt.plot(range(EPOCHS), val_loss, label='Doğrulama Kaybı')\nplt.legend(loc='upper right')\nplt.title('Eğitim ve Doğrulama Kaybı')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Nihai Model Performansı\nEğitim sürecinin görsel analizinden sonra, modelin nihai performansı doğrulama seti üzerinde sayısal metriklerle değerlendirilmiştir. `Classification Report` her bir sınıf için precision, recall ve f1-score değerlerini sunarken, `Confusion Matrix` modelin hangi sınıfları birbiriyle karıştırdığını görsel olarak göstermektedir.","metadata":{}},{"cell_type":"code","source":"# Adım 7: Nihai Model Değerlendirmesi\nprint(\"\\n--- NİHAİ MODEL DEĞERLENDİRMESİ ---\")\nvalidation_generator.reset()\nY_pred = model.predict(validation_generator, steps=validation_generator.samples // BATCH_SIZE + 1)\ny_pred = np.argmax(Y_pred, axis=1)\ny_true = validation_generator.classes\n\nprint(\"\\nClassification Report\")\nprint(classification_report(y_true, y_pred, target_names=class_names))\n\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Tahmin Edilen')\nplt.ylabel('Gerçek')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Sonuç ve Proje Özeti\nBu projenin sonucunda, Transfer Learning ve `EfficientNetB0` mimarisi kullanılarak 10 farklı maymun türünü sınıflandıran yüksek başarılı bir model geliştirilmiştir. Veri çoğaltma ve düşük öğrenme oranı gibi optimizasyon teknikleri sayesinde modelin ezberleme yapması engellenmiş ve doğrulama seti üzerinde **~%97** gibi oldukça yüksek bir doğruluk oranına ulaşılmıştır. Bu sonuç, projenin başlangıcında belirlenen hedeflere başarıyla ulaşıldığını göstermektedir.","metadata":{}}]}